{
    "selection_percentile": 59,
    "selection_rf_max_feats": 68,
    "learning_rate": 0.04257472485535299,
    "batch_size": 210,
    "max_epochs": 14,
    "depth": 1,
    "width_layer1": 44,
    "dropout_layer1": 0.2844786902367659,
    "activation_layer1": "nn.ReLU",
    "dropout_layer2": 0.21381410933208195,
    "activation_layer2": "nn.SiLU"
}